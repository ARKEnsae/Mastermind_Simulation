---
title: "Mastermind et permutations"
author: "Kim Antunez, Romain Lesauvage, Alain Quartier-la-Tente"
header-includes:
- \renewcommand{\P}{\mathbb{P}}
- \renewcommand{\R}{\mathbb{R}}
- \renewcommand{\N}{\mathbb{N}}
- \newcommand\1{\mathbb{1}}
- \newcommand\E{\mathbb{E}}
- \DeclareMathOperator*{\argmax}{argmax}
output: 
  bookdown::html_document2:
    toc: true
    number_sections: true
bibliography: biblio.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      cache = TRUE)
library(knitr)
library(kableExtra)
```

```{r firstProg, echo=FALSE}
# source("../ShinyApp/global.R", encoding="UTF-8",chdir = TRUE)
set.seed(1)
options(knitr.kable.NA = ' ')
creation_tableau <- function(tab, titre = "", note_debut = NULL, note_fin = NULL){
  tableau <- tab %>%
    cbind(" " = "n", "  " = rownames(.), .)
  rownames(tableau) <- NULL
  note <- c("Statistiques sur 10 seeds",
            "N = 5 x n x m simulations",
            "Au maximum 100 itérations")
  note <- c(note_debut, note, note_fin)
  tableau %>% 
    kable(caption = titre) %>%
    kable_styling(full_width = F)%>%
    column_spec(1:2, bold = T) %>% 
    collapse_rows(columns = 1, valign = "middle") %>% 
    add_header_above(c(" " = 2, "m" = 7)) %>% 
    footnote(general = note, general_title = "Note : ")
}
```
$$\renewcommand{\P}{\mathbb{P}}
\renewcommand{\R}{\mathbb{R}}
\renewcommand{\N}{\mathbb{N}}
\newcommand\1{\mathbb{1}}
\newcommand\E{\mathbb{E}}
\DeclareMathOperator*{\argmax}{argmax}$$

# Introduction



Ce rapport décrit le projet de Monte-Carlo de Kim Antunez, Romain Lesauvage et Alain Quartier-la-Tente (Ensae, 2A), dont l'objectif est d'étudier l'application de méthodes de *Cross-Entropy* à la résolution du Mastermind.

Le Mastermind est un jeu à deux joueurs, où le premier joueur choisit un *code* (une séquence de $n$ boules de couleur, parmi $m$ couleurs possibles)
^[Les valeurs standards sont $m = 6$ couleurs et $n=4$ boules],
et le second joueur doit deviner ce code en un minimum de coups. 
À chaque coup, le second joueur propose un code, et le premier joueur doit lui donner :

a. le nombre de boules bien placées : c'est que ce nous appelons le *nombre de boules noires* ;  
b. le nombre de boules de la bonne couleur, mais mal placées : c'est que ce nous appelons le *nombre de boules blanches*.

Par exemple, si le code à décoder est "vert-bleu-rouge-violet" et que le second joueur propose "violet-rouge-rouge-jaune" alors il y a une boule noire (une des boules rouges est bien placée) et une boule blanche (il y a bien une boule violette mais elle est mal placée).

L'objectif de ce projet est d'appliquer trois méthodes différentes pour résoudre ce problème :

1. Mettre en oeuvre un algorithme basé sur la méthode *Cross-Entropy* (section \@ref(sec:q1)).

2. Adapter la méthode précédente au cas où le premier joueur doit forcément choisir une permutation comme code (i.e. chaque couleur ne peut apparaître qu’une seule fois, donc $m \ge n$) (section \@ref(sec:q2)).

3. En utilisant, au sein d'une approche de *Cross-Entropy*, la loi suivante sur l'ensemble des permutations (section \@ref(sec:q3)) :
$$
\pi_{\lambda, x^*}(x)\propto\exp{(−\lambda d(x, x^{*}))}
$$
Avec $\lambda > 0$ et $d(x, x^{*})$ la distance de Hamming entre $x$ et $x^{*}$ (i.e. : le nombre de où les deux permutations sont différentes).

Tous les codes utilisés sont disponibles dans la partie \@ref(sec:enscode).

## Rappels sur la méthode de *Cross-Entropy*

La méthode de *Cross-Entropy* est une méthode utilisée pour estimer des probabilités d'événements rares. Elle peut aussi être adaptée pour résoudre des problèmes d'optimisation combinatoire et c'est dans ce cadre que nous l'utiliserons dans notre projet.

Le problème est le suivant : soit $\mathcal{X}$ un ensemble fini d'états et $S$ une fonction de score. L'objectif est de trouver le maximum de $S$ sur $\mathcal{X}$ (noté $\gamma^{*}$) et les points pour lesquels ce maximum est atteint ($x^*$). Si on note $\gamma^{*}$ ce maximum, on cherche donc :
\begin{equation} 
S(x^{*})=\gamma^{*}=\underset{x\in\mathcal{X}}{{\max}} S(x)
  (\#eq:defscore)
\end{equation} 
Pour le résoudre, on lui associe un problème stochastique d'estimation de probabilité d'événements rares. On définit :

- un ensemble d'indicatrices $\1_{\left\{ S(x)\geq\gamma\right\}}$ sur $\mathcal{X}$ pour plusieurs seuils $\gamma\in\mathbb{R}$ ;  
-  $\{f(\cdot;v),\,v\in\mathcal{V}\}$ une famille discrète de probabilités sur $\mathcal{X}$, paramétrée par un paramètre vectoriel $v$. 

Pour $u\in\mathcal{V}$, le problème \@ref(eq:defscore) est équivalent au problème d'estimation de la probabilité :
$$\mathbb{P}_{u}(S(X)\geq\gamma)=\sum_{x}\1_{\{S(x)\geq\gamma\}}f(x;u)=\mathbb{E}_{u}[\1_{\{S(x)\geq\gamma\}}]$$

---

L'algorithme utilisé est le suivant :

1. Initialisation : on fixe arbitrairement $\hat{v}_{0}$, deux paramètres $N\in \mathbb N$ et $\rho\in]0,1[$, $t = 1$.  
2. On génère un échantillon $X_{1},\dots,X_{N}$ de loi $f(\cdot,v_{t-1})$, on calcule le quantile $(1-\rho)$ de la fonction score qui donne $\hat{\gamma}_{t}$ :
$$\hat{\gamma}_{t}=S_{\lceil(1-\rho)N\rceil}$$
Si $\hat{\gamma}_{t}\geq\gamma^*$ on prend $\hat{\gamma}_{t}=\gamma^*$.  
3. On utilise le même échantillon $X_{1},\dots,X_{N}$ pour trouver $\hat{v}_{t}$ :
\begin{equation} 
\DeclareMathOperator*{\argmax}{argmax}
\hat{v}_{t}=\underset{v}{\argmax}\;\hat{D}(v)=\underset{v}{\argmax}\frac{1}{N}\sum_{i=1}^{N}\1_{\{S(X_{i})\geq\hat{\gamma}_{t}\}}\ln f(X_{i};v)
  (\#eq:maxopti)
\end{equation} 
4. Arrêt : si pour un certain $t\geq d$, (par exemple $d=5$), on a : 
$$\hat{\gamma}_{t}=\hat{\gamma}_{t-1}=\dots=\hat{\gamma}_{t-d}$$
alors on arrête l'algorithme.

---

### Smoothed updating

Plutôt que de mettre à jour directement $\hat{v}_{t-1}$ l'équation \@ref(eq:maxopti), nous faisons une mise à jour lissée -- \emph{smoothed updating} :
$$
\hat{v}_{t}=\alpha\tilde{v}_{t}+(1-\alpha)\hat{v}_{t-1}
$$
avec $\tilde{v}_{t}$ la valeur obtenue en résolvant le problème \ref{eq:maxopti}. 
Dans le cas où on a des problèmes d'optimisation avec des variables discrètes (ce qui est ici le cas), cela permet d'éviter l'occurence de 0 ou de 1 dans les paramètres des vecteurs. 
En effet, dès lors qu'il y a un 0 ou un 1, le problème est qu'il le
reste souvent pour toujours : cela évite d'avoir uen convergence vers la mauvaise valeur. @de2005tutorial suggèrent de prendre $0,4\leq\alpha\leq0,9$ : dans ce projet nous utilisons par défaut $\alpha = 0,7$.

# Application de la méthode de *Cross-Entropy* au Mastermind {#sec:q1}


## Paramètres utilisés dans le projet

Dans ce projet  sur le Mastermind, la fonction $S$ de score correspond à la réponse du joueur 1 : plus il est grand plus le joueur 2 est proche de la bonne réponse. Pour toute proposition $x$ on a :
$$
S(x)=\frac{\omega_{noir}\times N_{\text{boules noires}}+\omega_{blanc}\times N_{\text{boules blanches}}
}{
\omega_{noir}\times n
}
$$
Avec $n$ le nombre de boules à deviner, $\omega_{noir}>\omega_{blanc}$, habituellement $\omega_{noir}=2$ et $\omega_{blanc}=1$.

Avec cette fonction de score nous supposons qu'une boule noire compte plus qu'une boule blanche. La constante de normalisation $\omega_{noir}\times n$ permet de faciliter les comparaisons lorsque l'on fait changer le nombre de boules à deviner : dans tous les cas on cherche $x^*$ tel que $S(x^*) = 1$.

Dans l'algorithme de *Cross-Entropy* nous utilisons $\rho = 0,1$ (à l'étape 3 la maximisation est donc faite sur les 10 \% meilleurs échantillons), $N = C\times\text{nombre de paramètres à estimer}$ (avec $C=5$ par défaut) et $d=5$.

## Application de la méthode de *Cross-Entropy*

Dans le Mastermind il faut choisir $n$ boules parmi $m$ couleurs. En numérotant les couleurs de 1 à $m$ on a :

- $\mathcal{X}=\left\{ 1,2,\dots,m\right\}^{n}$  

-   Pour générer les échantillons, la famille de lois utilisée est :
$$\mathcal{V} = \left\{ \left(p_{i,j}\right)_{i,j} \in\mathcal{M}_{n,m}([0,1])\::\:\forall i,\sum_{j=1}^mp_{i,j}=1\right\} $$
Ainsi, les composantes du vecteur $X=(X_{1},\dots,X_{n})\in\mathcal{X}$ sont tirées aléatoirement de façons à ce que leur distribution soit
déterminée par une suite $p_{1},\dots,p_{n}$ de vecteurs de probabilités.
La $j$ \ieme composante de $p_{i}$ étant égale à $p_{ij}=\P(X_{i}=j)$ : c'est la probabilité d'avoir une boule de couleur $j$ en $i$ème position.

- L'initialisation est faite avec des vecteurs de probabilité uniformes pour chaque couleur : 
$$
\hat{v}_{0}=\left(\frac{1}{m}\right)_{i=1..n,j=1..m}
$$
Pour estimer de manière optimale on utilise la formule (voir démonstration partie \@ref(sec:demmajparam)) :
$$p_{k,l}=\frac{\sum_{i=1}^{N}\1_{\{S(X_{i})\geq\hat{\gamma}_{t}\}}\1_{\left\{ X_{i,k}=l\right\} }}{\sum_{i=1}^{N}\1_{\{S(X_{i})\geq\hat{\gamma}_{t}\}}}$$
- À chaque itération nous générons $N = C\times m\times n$ échantillons. Pour générer $X=(X_{1},\dots,X_{n})\in\mathcal{X}$, nous pouvons générer chaque composante $X_i$ de manière indépendante : il s'agit d'une loi discrète sur $\left\{ 1,2,\dots,m\right\}$ avec des probabilités $p_i=(p_{i,1},\dots,p_{i,m})$. Pour cela, sous R il suffit d'utiliser la fonction `sample` en utilisant l'option `prob` pour définir le vecteur de probabilités. Cette fonction peut être réécrite aisément à l'aide d'un tirage d'une loi uniforme discrète. Pour cela, prenons un nombre très grand, par exemple $k=$ 100 000, et créons un vecteur contenant des entiers de 1 à $m$, chaque élément $j$ étant répété $k\times p_{i,j}$ fois. En tirant une position au hasard dans ce vecteur (i.e. en tirant un entier au hasard entre 1 et $k$), l'entier associé sera égal à $j$ avec une probabilité environ égale à $p_{i,j}$. Sous R on peut coder cette fonction de la façon suivante :

```{r sample2}
sample2 <- function(x, size, prob, replace = TRUE){
  taille <- 10000*length(x)
  choix <- lapply(seq_along(x), function(i){
    rep(x[i], round(prob[i]*taille))
  })
  choix <- unlist(choix)
  if(replace){
    resultat = sapply(seq_len(size), function(i){
      indice = as.integer(runif(1,1,taille+1))
      choix[indice]
    })
    
  } else {
    resultat = vector(mode = mode(x),
                      length = size)
    sous_choix = choix
    for(k in 1:size){
      taille_sc = length(sous_choix)
      indice = as.integer(runif(1,1,taille_sc+1))
      resultat[k] = sous_choix[indice]
      sous_choix = sous_choix[sous_choix != sous_choix[indice]]
    } 
  }
  resultat
}
set.seed(1)
prob = c(1/4, 1/3, 5/12) # soit : 0.250, 0.333 et 0.417
# On retrouve les proportions :
table(sample2(x=1:3,size = 100000, prob = prob, replace = T))/100000
```

## Résultats



```{r test, fig.width=4, fig.cap="Graphics test", fig.subcap=c("test1", "test2")}
knitr::include_graphics(c("img/LOGO-ENSAE.png", "img/LOGO-ENSAE.png"))
```

Graphique pour représenter la convergence des probas dans un cas simple

Les tableaux \@ref(tab:tabq1convmed), \@ref(tab:tabq1erreur), \@ref(tab:tabq1tempsconv) et  \@ref(tab:tabq1nbnonconv) présentent les résultats sur plusieurs valeurs de $m$ et $n$ avec 10 simulations pour chaques paramètres (seed de 1 à 10). Pour toutes les simulations on a une convergence en moins de 100 itérations mais pas forcément vers la bonne valeur (voir tableaux  \@ref(tab:tabq1erreur) et \@ref(tab:tabq1nbnonconv)).


```{r tabq1convmed, echo=FALSE}
stats <- readRDS("Resultats/statsq1.RDS")
creation_tableau(stats$it_conv_med, titre = "Médiane du numéro de simulation de convergence")
```

```{r tabq1erreur, echo=FALSE}
creation_tableau(round(stats$erreur_finale,3), titre = "Moyenne de l'erreur à la simulation de convergence",
                 note_debut = "L'erreur est définie comme 1 - gamma_T")
```

```{r tabq1nbnonconv, echo=FALSE}
creation_tableau(stats$nb_non_conv,
                 titre = "Nombre de simulations n'ayant pas convergé vers la bonne valeur")
```

```{r tabq1tempsconv, echo=FALSE}
creation_tableau(stats$temps_conv,
                 titre = "Mediane du temps de calcul jusqu'à la convergence")
```



## Démonstration de la formule de mise à jour des paramètres {#sec:demmajparam}

La densité s'écrit :
$$
f(X;p)=\prod_{i=1}^{n}\prod_{j=1}^{m}p_{i,j}^{\1_{\left\{ X_{i}=j\right\} }}
$$

Il vient :
$$
\ln f(X;p)=\sum_{i=1}^{n}\sum_{j=1}^{m}\1_{\left\{ X_{i}=j\right\} }\ln p_{i,j}
$$
Et :
$$
\frac{\partial}{\partial p_{k,l}}\ln f(X;p)=\frac{\partial}{\partial p_{k,l}}\sum_{j=1}^{m}\1_{\left\{ X_{k}=j\right\} }\ln p_{k,j}=\frac{\1_{\left\{ X_{k}=l\right\} }}{p_{k,l}}
$$

Soit maintenant un échantillon de taille $N$, $X_{1},\dots,X_{N}\overset{i.i.d}{\sim}X$. Notons$X_{i}=(X_{i,1},\dots,X_{i,n})\in\mathcal{X}$. Le programme
de maximisation \ref{eq:maxopti} s'écrit comme un problème de maximisation sous
contrainte :
$$
\begin{cases}
\underset{p_{i,j}}{\max} & \sum_{i=1}^{N}\1_{\{S(X_{i})\geq\hat{\gamma}_{t}\}}\ln f(X_{i};v)\\
s.c & \forall i\::\:\sum_{j=1}^{m}p_{i,j}=1
\end{cases}
$$
Le Lagrangien s'écrit :
$$
\mathcal{L}=\sum_{i=1}^{N}\1_{\{S(X_{i})\geq\hat{\gamma}_{t}\}}\ln f(X_{i};v)+\sum_{i=1}^{n}\lambda_{i}\left(\sum_{j=1}^{m}p_{i,j}-1\right)
$$

La condition d'optimalité en $p_{k,l}$ :
$$
\frac{\partial}{\partial p_{k,l}}\mathcal{L}=0\implies\sum_{i=1}^{N}\1_{\{S(X_{i})\geq\hat{\gamma}_{t}\}}\frac{\1_{\left\{ X_{i,k}=l\right\} }}{p_{k,l}}-\lambda_{k}=0
$$

Soit : 
$$
\sum_{i=1}^{N}\1_{\{S(X_{i})\geq\hat{\gamma}_{t}\}}\1_{\left\{ X_{i,k}=l\right\} }=\lambda_{k}p_{k,l}
$$

En sommant sur $l$ et en utilisant la condition sur les $p_{i,j}$, il vient :
$$
\lambda_{k}=\sum_{i=1}^{N}\1_{\{S(X_{i})\geq\hat{\gamma}_{t}\}}\underbrace{\sum_{l=1}^{m}\1_{\left\{ X_{i,k}=l\right\} }}_{=1}
$$

D'où la formule de mise à jour :

$$
p_{k,l}=\frac{\sum_{i=1}^{N}\1_{\{S(X_{i})\geq\hat{\gamma}_{t}\}}\1_{\left\{ X_{i,k}=l\right\} }}{\sum_{i=1}^{N}\1_{\{S(X_{i})\geq\hat{\gamma}_{t}\}}}
$$


# Restriction aux permutations

Dans cette partie nous supposons que le premier joueur doit forcément choisir comme code une permutation (chaque couleur ne peut apparaître plus d'une fois et $m\geq n$).

## Adaptation de l'algorithme précédent {#sec:q2}

L'énoncé suggère de garder le même algorithme de génération mais en adaptant le mécanisme de génération pour générer des permutations. En notant encore $P=(p_{i,j})$ la matrice des paramètres associée à $X=(X_{1},\dots,X_{n})\in\mathcal{X}$, $X$ est généré de la façon suivante :

1. Initialisation : la première boule est générée de la même façon que précédemment en tirant un entier $x_1$ selon la loi de probabilité discrète donnée par $p_{1,\cdot} = (p_{1,1},\dots, p_{1,m})$. On pose $k=1$ et $P^{(1)} = P$.

2. Itération : $P^{(k+1)}$ est obtenue en remplaçant la colonne $k$ de $P^{(k)}$ par 0 et en normalisant les lignes pour que leur somme valent 1. $x_{k+1}$ est alors obtenu en faisant un tirage d'une loi discrète donnée par la ligne $k+1$ de $P^{(k+1)}$. Sous R, il n'est pas nécessaire de renormaliser ses lignes, cela est pris en compte par le paramètre `prob` de la fonction `sample`.

3. Si $k=n$ alors on arrête, sinon on pose $k=k+1$ et on répéte l'étape 2.


Comme suggéré par l'énoncé, les autres étapes de l'algorithme restent les mêmes :

- L'initialisation est faite avec des vecteurs de probabilité uniformes pour chaque couleur : 
$$
\hat{v}_{0}=\left(\frac{1}{m}\right)_{i=1..n,j=1..m}
$$
Pour estimer de manière optimale on utilise la formule :
$$p_{k,l}=\frac{\sum_{i=1}^{N}\1_{\{S(X_{i})\geq\hat{\gamma}_{t}\}}\1_{\left\{ X_{i,k}=l\right\} }}{\sum_{i=1}^{N}\1_{\{S(X_{i})\geq\hat{\gamma}_{t}\}}}$$  
- À chaque itération nous générons $N = C\times m\times n$ échantillons.

La méthode d'estimation utilisée dans la partie précédente pour mettre à jour les $p_{i,j}$ reste la même. En effet $P=(p_{i,j})$ s'interprète de la même façon que précédemment : la loi des $X_i$ est la même. De la même façon que dans la partie \@ref(sec:demmajparam), on peut montrer que la formule de mise à jour des paramètres s'écrit :
$$p_{k,l}=\frac{
\sum_{i=1}^{N}\1_{\{S(X_{i})\geq\hat{\gamma}_{t}\}}\1_{\left\{ X_{i,k}=l\right\} }
\1_{\{X_{i}\text{ permutation}\}}
}{
\sum_{i=1}^{N}\1_{\{S(X_{i})\geq\hat{\gamma}_{t}\}}
\1_{\{X_{i}\text{ permutation}\}}
}$$

Il est donc possible de mettre à jour les paramètres en appliquant la méthode de génération des échantillons de la partie \@ref(sec:q1). En revanche, dans ce cas, beaucoup d'échantillons ne seraient plus pertinents. Le nouvel algorithme de génération permet juste d'améliorer le processus de génération en ne proposant que des candidats pertinents, et donc d'avoir une convergence plus rapide. Puisque l'on ne génère que des permutations, on a $\1_{\{X_{i}\text{ permutation}\}} = 1$ et on retrouve la formule précédente.

### Résultats

Les tableaux \@ref(tab:tabq2convmed), \@ref(tab:tabq2erreur), \@ref(tab:tabq2tempsconv) et  \@ref(tab:tabq2nbnonconv) présentent les résultats sur plusieurs valeurs de $m$ et $n$ avec 10 simulations pour chaques paramètres (seed de 1 à 10). Pour toutes les simulations on a une convergence en moins de 100 itérations vers la bonne valeur.


```{r tabq2convmed, echo=FALSE}
stats <- readRDS("Resultats/statsq2.RDS")
creation_tableau(stats$it_conv_med, titre = "Médiane du numéro de simulation de convergence")
```

```{r tabq2erreur, echo=FALSE}
creation_tableau(round(stats$erreur_finale,3), titre = "Moyenne de l'erreur à la simulation de convergence",
                 note_debut = "L'erreur est définie comme 1 - gamma_T")
```

```{r tabq2nbnonconv, echo=FALSE}
creation_tableau(stats$nb_non_conv,
                 titre = "Nombre de simulations n'ayant pas convergé vers la bonne valeur")
```

```{r tabq2tempsconv, echo=FALSE}
creation_tableau(stats$temps_conv,
                 titre = "Mediane du temps de calcul jusqu'à la convergence")
```

Les tableaux \@ref(tab:tabq1vsq2convmed), \@ref(tab:tabq1vsq2erreur), \@ref(tab:tabq1vsq2nbnonconv) et \@ref(tab:tabq1vsq2tempsconv) présentent les résultats obtenus en utilisant l'algorithme de la partie \@ref(sec:q1), qui ne suppose pas que l'on ait des permutations, sur les mêmes codes à déchiffrer. Même si le nombre d'itérations nécessaires pour converger est plus faible en adaptant l'algorithme pour ne tirer que des permutations, l'algorithme est plus gourmand en temps de calcul. Cela vient du mécanisme utilisé pour tiré les échantillons qui a une complexité plus importante.

```{r tabq1vsq2convmed, echo=FALSE}
stats <- readRDS("Resultats/statsq1vsq2.RDS")
creation_tableau(stats$it_conv_med, titre = "Médiane du numéro de simulation de convergence")
```

```{r tabq1vsq2erreur, echo=FALSE}
creation_tableau(round(stats$erreur_finale,3), titre = "Moyenne de l'erreur à la simulation de convergence",
                 note_debut = "L'erreur est définie comme 1 - gamma_T")
```

```{r tabq1vsq2nbnonconv, echo=FALSE}
creation_tableau(stats$nb_non_conv,
                 titre = "Nombre de simulations n'ayant pas convergé vers la bonne valeur")
```

```{r tabq1vsq2tempsconv, echo=FALSE}
creation_tableau(stats$temps_conv,
                 titre = "Mediane du temps de calcul jusqu'à la convergence")
```


## Utilisation d'une loi spécifique pour générer les permutations {#sec:q3}

Dans cette partie on utilise la loi suivante sur l'ensemble des permutations :
$$
\pi_{\lambda, x^*}(x)\propto\exp{(−\lambda d(x, x^{*}))}
$$
Pour générer les échantillons on utilise l'algorithme de Metropolis-Hastings (voir partie \@ref(sec:mh)). Pour la mise en oeuvre de la méthode de *Cross-Entropy*, on va mettre à jour $\lambda$ et $x^*$ à chaque itération. Le critère d'arrêt qui est utilisé est $x^*=y$ (i.e. $S(x^*)=1$).

Nous avons ici $n+1$ paramètres à estimer ($n$ pour $x^*$ et 1 pour $\lambda$). Nous générons donc $N = C\times (n+1)$ échantillons à chaque itération de la *Cross-Entropy*.

### Génération de l'échantillon {#sec:mh}

#### Algorithme de Metropolis-Hastings

Pour générer les échantillons $X_1,\dots,X_n\sim \pi_{\lambda, x^*}$ on utilise l'algorithme de Metropolis-Hastings où le mécanisme de proposition inverse deux éléments de la permutation. Pour $m=n$, les $X_i$ sont des vraies permutations sur $\{1,\dots,m\}$. Puisque le mécanisme de proposition est symétrique, l'algorithme de Metropolis-Hasting devient :

L'algorithme de Metropolis-Hastings est le suivant :

1. Initialisation : on choisit $x_0$ une permutation au hasard de $\{1,\dots,m\}$ et on fixe $t=0$.

2. Itération :  

  a. On permute au hasard deux éléments de $x_t$ et on note $x'$ la nouvelle permutation (on fait donc une transposition de $x_t$).
  
  b. On calcule la probabilité d'acceptation :
$$
r(x',x_t)=\min\left(1,\,\frac{\pi_{\lambda,x^*}(x')}{\pi_{\lambda,x^*}(x_{t})}\right)
=\min\left(1,\,\mathrm{e^{-\lambda(d(x',x^{*})-d(x_{t},x^{*}))}}\right)
$$  

  c. Acceptation ou rejet : on génére une loi uniforme $u\in[0,1]$. Si $u \leq r(x',x_{t}) $ alors on accepte le nouvel état et on pose $x_{t+1}=x'$, sinon $x_{t+1}=x_{t}$.
  
  d. Incrémentation : $t=t+1$.

Dans le cas où $m>n$, $x^*$ ne peut être une vraie permutation. Pour générer la loi dans ce cas, nous raisonnons de la même façon en modifiant deux étapes :

 - dans le mécanisme de proposition nous inversons deux coordonnées mais en imposant qu'au moins une des deux soit plus petite que $n$ ;
 
 - dans le calcule de la probabilité d'acceptation nous ne calculons la distance de Hamming que sur les $n$ premières coordonnées $x'$ et $x_t$ (comme $x^*$ est un vecteur de taille $n$) ;

Comme $x'$ est une transposition de $x_t$, $d(x',x^{*})-d(x_{t},x^{*})\in\{-2,-1,0,1,2\}$. Donc si, par rapport à $x_t$ dans $x'$ ne diminue pas la distance de Hamming à $x^{*}$ alors on accepte le nouvel état. S'il y a nouvel élément mal placé alors on accepte $x'$ avec une probabilité de $e^{-\lambda}$ : pour $\lambda>2$ la probabilité d'accepter un nouvel état moins proche que $x_t$ de $x^*$ est donc inférieure à 14 % et pour $\lambda>3$ cette probabilité inférieure à 5 %. Pour $\lambda$ grand on converge donc vers $x^*$ et tous les échantillons seront égaux à $x^*$.

#### Traitement supplémentaires


L'algorithme de Metropolis-Hastings a deux désavantages :

1. Il générer la loi cible, il construit itérativement une chaîne de Markov qui converge vers cette loi cible. Les échantillons initiaux peuvent donc suivre une distribution très différente de celle recherché. Il est donc nécessaire de rejetter une partie importante des échantillons initiaux (*burn-in*). C'est corrigé en enlevant les $250\times m$ premières observations (voir partie \@ref(subsec:burnin)).

2. Par construction, les échantillons proches sont corrélés entre eux. Pour générer des échantillons indépendants il faut donc en rejeter et ne garder que les $n$^ièmes^ échantillons. Dans notre cas nous prenons $n=100$ pour toutes les simulations  (voir partie \@ref(subsec:acf)).

#### Gestion du burn-in {#subsec:burnin}

#### Gestion des autocorrélations {#subsec:acf}

Par construction, du fait du mécansime de proposition utilisé, les échantillons proches sont corrélés. Cette autocorrélation peut-être calculée avec la fonction `portes::LjungBox` (la fonction `acf` ne calculant les autocorrélations que pour les séries univariées). En revanche, intégrer ce test dans le mécanisme de proposition est très couteux en temps. Garder tous les 80^ièmes^ écorrige ce problème : on ne rejette pas les tests de LjungBox d'indépendance des échantillons au seuil de 10 % pour tous les paramètres testés.

Les graphiques \@ref(fig:acfn10m40) à \@ref(fig:acfn20m40corr) montrent les autocorrélogrammes des 4 premières composantes (i.e. : 4 premières boules) pour $n=10$ et $m=40$ et $n=20$ et $m=40$. Le tableau \@ref(tab:tabcorrlb) montre qu'avec ce pas de 80 les échantillons générés sont bien indépendants.

```{r acfn10m40, echo = FALSE, fig.cap="Autocorrélogrammes des quatres premières composantes des échantillons avec lambda = 1, n = 10 et m = 40"}
knitr::include_graphics("img/acfn10m40.png")
```

```{r acfn10m40corr, echo = FALSE, fig.cap="Autocorrélogrammes des quatres premières composantes des échantillons avec un pas de 80, lambda = 1, n = 10 et m = 40"}
knitr::include_graphics("img/acfn10m40corr.png")
```

```{r acfn20m40, echo = FALSE, fig.cap="Autocorrélogrammes des quatres premières composantes des échantillons avec lambda = 1, n = 20 et m = 40"}
knitr::include_graphics("img/acfn20m40.png")
```

```{r acfn20m40corr, echo = FALSE, fig.cap="Autocorrélogrammes des quatres premières composantes des échantillons avec un pas de 80, lambda = 1, n = 20 et m = 40"}
knitr::include_graphics("img/acfn20m40corr.png")
```

```{r tabcorrlb, echo=FALSE}
data_corr <- readRDS("Resultats/corr_n10m40n20m40.RDS")
note <- c("(H0) : échantillons indépendants contre (H1) ils sont corrélés.",
          "lambda = 1, x* tiré au hasard")
data_corr %>% 
  kable(caption = "Test de LjungBox en ne gardant qu'un échantillon sur 80") %>% 
kable_styling(full_width = F)%>%
  column_spec(1, bold = T) %>% 
  add_header_above(c(" " = 2,"n = 10, m = 40" = 3 ,"n = 20, m = 40" = 3)) %>% 
  footnote(general = note, general_title = "Note : ")
```


### Estimation des paramètres

@hongrois montre le problème de maximisation de la vraisemblance d'une loi de Mallow (qui est celle ici utilisée) peut se décomposer en deux étapes :

1. Estimation de $x^*$ qui minimise la somme des distances de Hamming.

2. Estimation de $\lambda$ par un algorithme de type Newton-Raphston.

L'estimation des paramètres dans l'algorithme de *Cross-Entropy* est équivalent à calculer l'estimateur de vraisemblance sur les 10 % meilleurs échantillons en terme de score. Intuitivement, le $x^*$ qui minimise la somme :
$$
\sum_{i=1}^N\1_{\{S(X_{i})\geq\hat{\gamma}_{t}\}}d(X_i,x^*)
$$
est le $x^*=(x_1^*,\dots,x_n^*)$ tel que $x_j^*$ correspond au chiffre le plus fréquent dans la $j$^ème^ coordonnée des 10 % meilleurs échantillons. L'algorithme décrit par @hongrois, et que nous utilisons dans notre projet, pat de ce principe mais en imposant que $x^*$ soit bien une permutation :

1. On crée une matrice $F=(f_{i,j})\in\mathcal M_{n,m}(\N)$ telle $f_{i,j}$ soit égal au nombre de fois que l'entier $j$ apparait en $i$^ème^ position parmi les 10 % meilleurs échantillon.

2. On sélectionne une composante par ligne et par colonne de $F$ de façon à ce que leur somme soit maximale. Cette étape est faite avec la fonction `clue::solve_LSAP`.

@hongrois montre que la constante de normalisation de $\pi_{\lambda,x^*}$ est en fait connue est égale à :
$$
m!\exp(-\lambda m)\sum_{k=0}^{m}\frac{(\exp(\lambda)-1)^{k}}{k!}
$$
Le maximum de vraisemblance est alors obtenu en prenant $\lambda$ tel que :
$$
\frac{
\exp(\lambda)\sum_{k=0}^{m-1}\frac{(\exp(\lambda)-1)^{k}}{k!} - 
m\sum_{k=0}^{m}\frac{(\exp(\lambda)-1)^{k}}{k!}
}{
\sum_{k=0}^{m}\frac{(\exp(\lambda)-1)^{k}}{k!}
} +
\frac{1}{\sum_{i=1}^N\1_{\{S(X_{i})\geq\hat{\gamma}_{t}\}}}\sum_{i=1}^N\1_{\{S(X_{i})\geq\hat{\gamma}_{t}\}}d(X_i,x^*) = 0
$$
Dans notre cas, le problème est que nous observant une croissance rapide de $\lambda$ à chaque itération de la méthode de *Cross-Entropy*. Ainsi, si $y$ n'est pas décodé dans les premières itérations (ce qui est souvent le cas pour $m$ et $n$ grands), les échantillons $X_i$ générés seront très proches de $x^*$ (voir partie \@ref(sec:mh)) et on ne trouvera pas $y$. 

Nous avons testé plusieurs approches pour $\lambda$ : en le faisant croître linéaire, décroître, constant et maximum de vraisemblance. La solution qui donnait les meilleurs résultats est de prendre $\lambda = 1$.

### Résultats


# Code {#sec:enscode}

Les packages nécessaires pour faire tourner l'ensemble des programmes sont : 

```{r installpackages, eval=FALSE}
install.packages(c("clue", "kableExtra", "mvtnorm", "plot3D", "portes", "shiny", 
                   "shinyjs", "shinyWidgets"))
library(clue)
library(kableExtra)
library(mvtnorm)
library(plot3D)
library(portes)
library(shiny)
library(shinyjs)
library(shinyWidgets)
```

Pour lancer l'application shiny :

```{r shinyapp, eval = FALSE}
library(shiny)
runGitHub("Mastermind_Simulation", "ARKEnsae",subdir = "shinyApp")
```

L'ensemble des fonctions pour générer un code et calculer le score sont ci-dessous :
```{r initialisation}
# Création du vecteur à deviner
initialiser_y <- function(m, n, avec_remise = TRUE){
  # Avec remise = Q1
  # Sans remise = Q2/3
  if(!avec_remise & m<n){
    return(NULL)
    stop()
  }
  
  y <- sample(1:m, n, replace = avec_remise)
  return(y)
}

# Le score est calculé de façon suivante :
# poids_noir * nb_boules_noires + poids_noir * nb_boules_blanches
# Le score maximal (lorsqu'on a la bonne réponse) est égal à poids_noir * nb billes à deviner
# Pour faciliter les comparaisons, on normalise par défaut le score en le divisant par ce nombre
# Nombre de boules noires = nombre de boules bien placées
# Nombre de boules blanches = nombre de boules de la bonne couleur mais mal placées
score <- function(x, y,
                  poids_noir = 2, poids_blanc = 1,
                  normalisation = TRUE){
  score = poids_noir * nb_boules_noires(x, y) * poids_blanc + nb_boules_blanches(x, y)
  if(normalisation){
    score = score / (poids_noir * length(x))   
  }
  return(score)
}

nb_boules_noires <- function(x, y){
  sum(x == y)
}

nb_boules_blanches <- function(x, y){
  # On enlève les bien placés
  sous_x <- x[x != y]
  sous_y <- y[x != y]
  if(length(sous_x) == 0)
    return(0)
  # Pour chaque couleur de sous_x, on regarde si elle est dans y 
  mal_places <- sapply(sous_x, function(x){
    length(grep(x, sous_y))>0
  })
  sum(mal_places)
}

```

Les fonctions ci-dessous sont utiles pour mettre en forme les résultats :

```{r fonctions_utiles}
dessiner_histo <- function(liste_matrice,indice,colors){
  if(!is.null(indice)){
    matrice=liste_matrice[[indice]]
    n = c(1:nrow(matrice))
    m = c(1:ncol(matrice))
    couleurs_graphe <- t(matrix(rep(1:length(m),length(n)),nrow=length(n),ncol=length(m),byrow=TRUE))
    
    par(mar = c(0,0,0,0))
    hist3D(m, n, t(matrice), zlim=c(0,1), colvar = couleurs_graphe,
           col = colors[1:ncol(matrice)],theta=50, phi=40, axes=TRUE,label=TRUE, ticktype="detailed", space=0.5, lighting=TRUE, light="diffuse", shade=0.5, alpha=0.6, xlab="",ylab="billes",zlab="",colkey=list(plot=FALSE))
    
  }
}

tableau_bilan <- function(modele,matriciel=TRUE){
  
  if(!is.null(modele$indices$indice_arret) | !is.null(modele$indices$indice_conv)){
    i <- max(modele$indices$indice_arret,modele$indices$indice_conv)
  } else{
    i <- modele$parametres$maxIters
  }
  
  if(matriciel){
    tableau <- data.frame(
      t = 1:i,
      s_max = round(modele$s_max[1:i],3),
      gammas_hat = round(modele$gammas_hat[1:i],3),
      min = round(unlist(sapply(modele$P_hat_liste,p_min_max)["min",1:i]),4),
      max_min =round(unlist(sapply(modele$P_hat_liste,p_min_max)["max_min",1:i]),4),
      min_max =round(unlist(sapply(modele$P_hat_liste,p_min_max)["min_max",1:i]),4),
      max = round(unlist(sapply(modele$P_hat_liste,p_min_max)["max",1:i]),4)
    )
  }else{
    tableau <- data.frame(
      t = 1:i,
      s_max = round(modele$s_max[1:i],3),
      gammas_hat = round(modele$gammas_hat[1:i],3),
      lambda=round(unlist(lapply(1:i,function(k){((modele$param_liste)[[k]])$lambda})),2),
      score_xstar= unlist(lapply(1:i,function(k){score(((modele$param_liste)[[k]])$x_star, modele$parametres$y)}))
    )

  }
  
  return(tableau)
  
}

mise_en_forme_tableau <- function(modele,matriciel=TRUE){
  
  tableau <- tableau_bilan(modele,matriciel)
  
  type_modele <- ifelse(!matriciel,"Loi avec distance de Hamming",ifelse(modele$parametres$avec_remise,"Tirage avec remise","Tirage sans remise"))
  
  parametres <- paste0(#" : ",
    "n = ", modele$parametres$n, " / ",
    "m = ", modele$parametres$m, " / ",
    "N = ", modele$parametres$N, " / ",
    "rho = ", modele$parametres$rho, " / ",
    "smoothing = ", ifelse(modele$parametres$smoothing,"oui","non"), " / ",
    ifelse(modele$parametres$smoothing, paste0("alpha = ", modele$parametres$alpha, " / "),""),
  #  "avec remise = ", ifelse(modele$parametres$avec_remise,"oui","non"), " / ",
    "d = ", modele$parametres$d
  )
  
  
  
  convergence <- paste0("Convergence : ",
                        ifelse(!is.null(modele$indices$indice_conv),paste0("Etape n°", modele$indices$indice_conv, " (",modele$duree$duree_conv," sec.)"),"Non"),
                        " / ",
                        "Arrêt : ",
                        ifelse(!is.null(modele$indices$indice_arret),paste0("Etape n°", modele$indices$indice_arret, " (",modele$duree$duree_arret," sec.)"),"Non")
  )
  
  tableau_joli <- kable(tableau, align = "c") %>%
    kable_styling(full_width = F) %>%
    footnote(general = paste0(type_modele,"\n",
             "Parametres : ",parametres,"\n",
             convergence,'\n',
             "Temps de calcul total : ", modele$duree$duree_totale, " sec."),
             general_title = "\nNote",
             title_format = c("italic", "underline")
    )
  tableau_joli <- gsub('\\bNA\\b', '  ', tableau_joli) #remove NA
  
  return(tableau_joli)
  
}
```


## Questions 1 et 2 {#sec:codeq1q2}

### Génération des échantillons

Pour générer les échantillons en prenant ou non en compte les fait que la solution est une permutation, on utilise les codes suivants :

```{r gen_algo_ce_classique}
initialisation_sample <- function(m, n, N, P_hat = NULL, avec_remise = TRUE){
  if(avec_remise){
    initialisation_sample_avec_remise(m, n, N, P_hat)
  } else{
    initialisation_sample_sans_remise(m, n, N, P_hat)
  }  
}
initialisation_sample_avec_remise <- function(m, n, N, P_hat){
  X <- matrix(nrow = N, ncol = n)
  for(i in 1:n){
    X[,i] <- sample(1:m, N, replace = TRUE, prob = P_hat[i,])
  }
  X
}
initialisation_sample_sans_remise <- function(m, n, N, P_hat){
  X <- matrix(nrow = N, ncol = n)
  for(it in 1:N){ #X : Nxn   Phat : nxm
    couleurs_restantes <- 1:m
    for(i in 1:n){
      if(length(couleurs_restantes)>1){
        X[it,i] <- sample(couleurs_restantes, 1,
                          prob = P_hat[i,couleurs_restantes])
      }else{
        X[it,i] <- couleurs_restantes
      }
      couleurs_restantes <- setdiff(couleurs_restantes,
                                    X[it,i])
    }
  }
  X
}
p_min_max <- function(matrice){
  max_min <- max(apply(matrice,1,min))
  min_max <- min(apply(matrice,1,max))
  min <- min(matrice)
  max <- max(matrice)
  
  return(list(min = min,
              max = max,
              min_max = min_max,
              max_min = max_min))
}

meilleure_proposition <- function(matrice){
  matrice_ordre <- apply(matrice,1,rank)  
  return(apply(matrice_ordre,2,function(x){which(x==max(x))[1]})) 
}
```


### Algorithme de Cross-Entropy

L'algorithme de *Cross-Entropy* est définit ci-dessous. Il faut utiliser l'option `avec_remise = FALSE` si on veut tester l'algorithme en ne générant que des permutations.

```{r algo_ce_classique}
lancer_algorithme <- function(y, n, m, N = C * m * n, maxIters = 100,
                              rho = 0.1, alpha = 0.7,
                              poids_blanc = 1, poids_noir = 2,
                              smoothing = TRUE, C = 5, d = 5,
                              stop_d = FALSE, avec_remise = TRUE){
  
  if(!avec_remise & m<n){
    stop()
  }
  
  duree = Sys.time()
  duree_arret = NULL
  duree_conv = NULL
  duree_totale= NULL
  
  # Création de la matrice P_hat initiale (n x m) 
  P_hat_tilde <- matrix(nrow = n, ncol = m)
  P_hat_liste <- list()
  P_hat_liste[[1]] <- matrix(1/m,nrow = n, ncol = m)
  # Listes à agrémenter
  #meilleur_score = 0
  #meilleur_scores = c()
  gammas_hat = c()
  s_max = c()
  
  indice_arret = NULL
  indice_conv = NULL
  
  ###### Algo
  
  
  #### début du try
  iter <- 0
  critere_arret <- TRUE
  #ceils = rounds each element of X to the nearest integer greater than or equal to that element.
  eidx = ceiling((1-rho)*N) #plus petit indice du meilleur Score.
  while(critere_arret & (iter+1)<= maxIters){
    iter <- iter + 1
    
    X <- initialisation_sample(m = m, n = n, N = N,
                               P_hat = P_hat_liste[[iter]],
                               avec_remise = avec_remise)
    
    #### Calcul du score
    
    scores <- apply(X, 1, score,
                    y = y, poids_noir = poids_noir, poids_blanc = poids_blanc)
    
    scores_tries <- sort(scores)
    
    # Mise à jour de Gamma 
    gamma = scores_tries[eidx]
    
    if(gamma==1 & is.null(duree_arret)){
      indice_arret <- iter
      duree_arret <- round(as.numeric(difftime(Sys.time(), duree),units="secs"),2)
    }
    
    s = scores_tries[N]
    #  meilleur_score = max(meilleur_score,  scores_tries[N]) #garder une trace du meilleur résultat
    gammas_hat[iter] = gamma
    s_max[iter] = s
    # meilleur_scores[iter] = meilleur_score
    
    for(i in 1:n){
      for(j in 1:m){
        P_hat_tilde[i,j]=sum(scores>=gamma & X[,i]==j)/sum(scores>=gamma)
      }
    }
    # Smoothing
    if(smoothing){
      #P_hat <- alpha * P_hat_tilde + (1-alpha)* P_hat_liste[[iter-1]]
      P_hat <- alpha * P_hat_tilde + (1-alpha)* P_hat_liste[[iter]] 
    } else{
      P_hat <- P_hat_tilde
    }
    
    P_hat_liste[[iter+1]] <- P_hat
    
    if(length(gammas_hat) > d & is.null(indice_conv)){
      gammas_d <- gammas_hat[(length(gammas_hat)-d):length(gammas_hat)]
      if(length(unique(gammas_d))==1){
        indice_conv <- iter
        duree_conv <- round(as.numeric(difftime(Sys.time(), duree),units="secs"),2)
        if(stop_d){
          critere_arret <- FALSE
        }
      }
    }
  }
 
  # On enlève la dernière P_hat non utile
  P_hat_liste <- P_hat_liste[-length(P_hat_liste)]
  
  ### fin de try
  duree_totale <- round(as.numeric(difftime(Sys.time(), duree),units="secs"),2)
  
   
  return(
    list(
      duree = list(
        duree_totale=duree_totale,
        duree_conv=duree_conv,
        duree_arret=duree_arret
        ),
      parametres=list(
        y=y,
        n=n,
        m=m,
        N=N,
        maxIters= maxIters,
        rho = rho,
        alpha = alpha,
        smoothing = smoothing,
        d=d,
        avec_remise = avec_remise
        
      ),
      
      
      P_hat_liste=P_hat_liste,
      s_max=s_max,
      gammas_hat=gammas_hat,
      indices = list(
        indice_arret = indice_arret,
        indice_conv = indice_conv
      )
    )
    
  )
}
m = 6
n = 4
set.seed(1)
y <- initialiser_y(m = m, n = n, avec_remise = TRUE)
y
resultat <- lancer_algorithme(y = y, n = n, m = m,
                              stop_d = TRUE) # Pour s'arrêter si convergence
mise_en_forme_tableau(resultat)
dessiner_histo(resultat$P_hat_liste, 
               3, # On trace l'histogramme des probabilités à l'itération 3
               c("#0000FF","#00FF00","#FF3232","#FFFF00","#CF00CF","#FFCFFF"))
dessiner_histo(resultat$P_hat_liste, 
               4, # On trace l'histogramme des probabilités à l'itération 4 
               c("#0000FF","#00FF00","#FF3232","#FFFF00","#CF00CF","#FFCFFF"))
```


## Question 3 {#sec:codeq3}

# Bilbiographie
